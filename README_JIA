How to build spark with spark-sql enabled:
    mvn -Pyarn -Phadoop-2.4 -Dhadoop.version=2.5.0 -Phive -Phive-thriftserver -DskipTests clean package

How to build a runnable distribution with spark-sql enabled:
    ./make-distribution.sh --name custom-spark --tgz -Pyarn -Phadoop-2.4 -Dhadoop.version=2.5.0 -Phive -Phive-thriftserver
    Then a dist/ folder will be generated and can be copied to different nodes for execution

How to view job history on UI after fact:
    0. Enable history log, and specify the history server port, otherwise default: 18080
        spark.eventLog.enabled true
        spark.history.ui.port 11510

    1. Start a history server
    ./sbin/start-history-server.sh

    2. Go to http://[master-url]:11510

    misc: the default directory to store history logs: /tmp/spark-events; 
          Only one history server can be launched at one time. 
          Stop it by ./sbin/stop-history-server.sh beore launching a new one


How to setup Spark cluster at ec2-cluster:
    Instructions: http://spark.apache.org/docs/latest/ec2-scripts.html
    Note: (1) by default it uses m1.large which incurs fees. To change this, use --instance-type
          (2) by default, it downloads spark from apache github page, and the default branch is 1.5.0, 
                this can be changes by specifying --spark-git-repo and --spark-version

    E.g. here is how to setup a cluster with three slaves:
    ./spark-ec2 -k initial-trial-key -i ../../../AWS/initial-trial-key.pem -s 3 --region=us-west-2 --zone=us-west-2a launch test

    E.g. here is to setup a cluster with specific instances and spark versions:
    ./spark-ec2 -k initial-trial-key -i ../../../AWS/initial-trial-key.pem -s 3 --region=us-west-2 --zone=us-west-2a --instance-type=m4.2xlarge --spark-git-repo=https://github.com/jaricftw/spark --spark-version=1.5.1 launch testm4


